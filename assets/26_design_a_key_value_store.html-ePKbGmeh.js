import{_ as e,o as t,c as a,f as r,e as i}from"./app-6TEM55KE.js";const s="/assets/system-design-55-aiG34JR9.png",n="/assets/system-design-56-vwWXwezj.png",d="/assets/system-design-57-6Rl1XRZP.png",l="/assets/system-design-58-AbinF-qb.png",o="/assets/system-design-59--6O3nXg3.png",g="/assets/system-design-60-nuUdNatE.png",p="/assets/system-design-61-VJPAvXw5.png",c="/assets/system-design-62-a7MB89e6.png",h="/assets/system-design-63-MDEQyUzP.png",u="/assets/system-design-64-Q2tfslLw.png",f="/assets/system-design-65-5RsDR0YC.png",m="/assets/system-design-66-KQfirbHD.png",_="/assets/system-design-67-9DB6YgX3.png",b="/assets/system-design-68-CqDfn1Uz.png",y="/assets/system-design-69-v8JxMcuR.png",x="/assets/system-design-70-nL8YuLzH.png",z={},k=i('<h1 id="_6-设计键值存储" tabindex="-1"><a class="header-anchor" href="#_6-设计键值存储" aria-hidden="true">#</a> 6. 设计键值存储</h1><p>键值存储（Key-Value Store）是一种非关系型数据库，具有以下特点：</p><ul><li>每个唯一标识符作为一个键（Key）存储，并与一个值（Value）关联。</li><li>键必须唯一，可以是明文字符串或哈希值。</li><li>从性能角度看，较短的键通常表现更优。</li></ul><p>示例键：</p><ul><li>明文键：<code>&quot;last_logged_in_at&quot;</code></li><li>哈希键：<code>253DDEC4</code></li></ul><p>我们将设计一个支持以下操作的键值存储系统：</p><ul><li><code>put(key, value)</code>：插入与 <code>key</code> 相关联的 <code>value</code>。</li><li><code>get(key)</code>：获取与 <code>key</code> 相关联的 <code>value</code>。</li></ul><h2 id="第一步-理解问题并确定设计范围" tabindex="-1"><a class="header-anchor" href="#第一步-理解问题并确定设计范围" aria-hidden="true">#</a> 第一步：理解问题并确定设计范围</h2><p>在设计系统时，需权衡读写性能与内存使用之间的关系。此外，数据一致性与系统可用性之间也存在取舍。</p><p>设计目标包括：</p><ul><li><strong>小型键值对</strong>：键值对的大小约为 10KB。</li><li><strong>大规模数据存储</strong>：系统应能存储海量数据。</li><li><strong>高可用性</strong>：系统即使在发生故障时也能快速响应。</li><li><strong>高可扩展性</strong>：系统需支持扩展以处理大数据集。</li><li><strong>自动扩展</strong>：根据流量自动添加或删除服务器。</li><li><strong>可调一致性</strong>。</li><li><strong>低延迟</strong>。</li></ul><h2 id="第二步-提出高层设计并获得认可" tabindex="-1"><a class="header-anchor" href="#第二步-提出高层设计并获得认可" aria-hidden="true">#</a> 第二步：提出高层设计并获得认可---</h2><h3 id="单机键值存储" tabindex="-1"><a class="header-anchor" href="#单机键值存储" aria-hidden="true">#</a> 单机键值存储</h3><p>单机键值存储实现简单。<br> 只需维护一个内存中的哈希表，用来存储键值对。然而，内存可能成为瓶颈，因为无法容纳全部数据。</p><p>扩展方式：</p><ul><li>数据压缩</li><li>仅将频繁使用的数据存储在内存中，其余存储在磁盘上</li></ul><p>即便如此，单台服务器的容量很快会达到上限。</p><hr><h3 id="分布式键值存储" tabindex="-1"><a class="header-anchor" href="#分布式键值存储" aria-hidden="true">#</a> 分布式键值存储</h3><p>分布式键值存储通过分布式哈希表（Distributed Hash Table）将键分配到多个节点上。设计时需要考虑 CAP 定理。</p><h4 id="cap-定理" tabindex="-1"><a class="header-anchor" href="#cap-定理" aria-hidden="true">#</a> CAP 定理</h4><p>CAP 定理指出，分布式系统无法同时满足以下三种属性：</p><ul><li><strong>一致性（Consistency）</strong>：所有客户端在任何时间点都能看到相同的数据。</li><li><strong>可用性（Availability）</strong>：所有客户端都能收到响应，即使某些节点发生故障。</li><li><strong>分区容错性（Partition Tolerance）</strong>：系统在部分节点间无法通信的情况下仍可正常工作。</li></ul><figure><img src="'+s+'" alt="CAP 定理" tabindex="0" loading="lazy"><figcaption>CAP 定理</figcaption></figure><p>在现实世界中，由于网络故障不可避免，支持一致性和可用性的分布式系统无法真正存在。</p><p>理想情况中的分布式数据存储示例：</p><figure><img src="'+n+'" alt="理想情况下的分布式系统" tabindex="0" loading="lazy"><figcaption>理想情况下的分布式系统</figcaption></figure><p>在现实中，网络分区可能阻止节点间通信，例如节点 3：</p><figure><img src="'+d+'" alt="网络分区示例" tabindex="0" loading="lazy"><figcaption>网络分区示例</figcaption></figure><p><strong>一致性优先</strong>：如果优先保证一致性，则上述情况下所有写操作会被阻塞。<br><strong>可用性优先</strong>：如果优先保证可用性，系统会继续接受读写请求，但可能返回过时数据。在节点 3 恢复后，会重新同步数据。</p><p>具体选择需要根据需求与面试官讨论。</p><h2 id="第三步-深入设计" tabindex="-1"><a class="header-anchor" href="#第三步-深入设计" aria-hidden="true">#</a> 第三步：深入设计</h2><p>以下是构建分布式键值存储的核心组件。</p><h3 id="数据分区" tabindex="-1"><a class="header-anchor" href="#数据分区" aria-hidden="true">#</a> 数据分区</h3><p>对于足够大的数据集，无法在单台服务器上维护，因此需要将数据分成多个分区并分布到多个节点上。</p><p>挑战在于：</p><ol><li>如何均匀分布数据？</li><li>在集群调整规模时，如何最小化数据迁移？</li></ol><p>通过一致性哈希（上一章讨论过）可以解决这些问题：</p><ul><li>将服务器映射到哈希环上。</li><li>对键进行哈希，并映射到顺时针方向最近的服务器。</li></ul><figure><img src="'+l+'" alt="一致性哈希" tabindex="0" loading="lazy"><figcaption>一致性哈希</figcaption></figure><p>优点：</p><ul><li><strong>自动扩展</strong>：可随意添加/删除服务器，且对键位置的影响最小。</li><li><strong>异构性</strong>：容量更高的服务器可以分配更多虚拟节点。</li></ul><hr><h3 id="数据复制" tabindex="-1"><a class="header-anchor" href="#数据复制" aria-hidden="true">#</a> 数据复制</h3><p>为实现高可用性和可靠性，需将数据复制到多个节点上。</p><p>可通过将键分配到哈希环上的多个节点实现：</p><figure><img src="'+o+'" alt="数据复制" tabindex="0" loading="lazy"><figcaption>数据复制</figcaption></figure><p>注意：复制时需避免所有副本分配到同一物理节点上。<br> 为此，可选择不同的物理节点。为进一步提高可靠性，可将数据复制到不同数据中心中，防止单个数据中心的故障。</p><hr><h3 id="一致性" tabindex="-1"><a class="header-anchor" href="#一致性" aria-hidden="true">#</a> 一致性</h3><p>数据复制后，需要保持同步。<br> 可以使用 <strong>Quorum 共识</strong> 来保证一致性：</p><ul><li><p><code>N</code>：副本数量</p></li><li><p><code>W</code>：写操作需确认的副本数量</p></li><li><p><code>R</code>：读操作需确认的副本数量</p><figure><img src="'+g+'" alt="写共识示例" tabindex="0" loading="lazy"><figcaption>写共识示例</figcaption></figure></li></ul><p><code>W</code> 和 <code>R</code> 的配置需权衡延迟与一致性：</p><ul><li><code>W = 1, R = 1</code>：低延迟，最终一致性</li><li><code>W + R &gt; N</code>：强一致性，高延迟</li></ul><p>其他配置：</p><ul><li><code>R = 1, W = N</code>：强一致性，快速读，写操作较慢。</li><li><code>R = N, W = 1</code>：强一致性，快速写，读操作较慢。</li></ul><h4 id="一致性模型" tabindex="-1"><a class="header-anchor" href="#一致性模型" aria-hidden="true">#</a> 一致性模型</h4><p>常见一致性模型：</p><ul><li><strong>强一致性</strong>：始终返回最新数据。</li><li><strong>弱一致性</strong>：可能返回旧数据。</li><li><strong>最终一致性</strong>：可能返回旧数据，但最终所有键都会达到最新状态。</li></ul><p>例如：Cassandra 和 DynamoDB 采用最终一致性。它允许并发写入，客户端负责解决数据冲突。</p><hr><h3 id="数据冲突解决-版本控制" tabindex="-1"><a class="header-anchor" href="#数据冲突解决-版本控制" aria-hidden="true">#</a> 数据冲突解决：版本控制</h3><p>复制提高了可用性，但可能引发数据不一致。例如：</p><figure><img src="'+p+'" alt="数据不一致示例" tabindex="0" loading="lazy"><figcaption>数据不一致示例</figcaption></figure><p>可使用向量时钟（Vector Clock）解决冲突。<br> 向量时钟是 [服务器, 版本] 对，记录数据版本变化：</p><figure><img src="'+c+'" alt="冲突解决示例" tabindex="0" loading="lazy"><figcaption>冲突解决示例</figcaption></figure><p>通过检测版本是否是祖先关系（版本戳是否小于另一版本）判断冲突：</p><ul><li><code>[s0, 1][s1, 1]</code> 是 <code>[s0, 1][s1, 2]</code> 的祖先 -&gt; 无冲突。</li><li><code>[s0, 1]</code> 不是 <code>[s1, 1]</code> 的祖先 -&gt; 需解决冲突。</li></ul><p>权衡点：</p><ul><li>增加客户端复杂性。</li><li>向量时钟可能迅速膨胀，增加内存开销。</li></ul><hr><h3 id="故障处理" tabindex="-1"><a class="header-anchor" href="#故障处理" aria-hidden="true">#</a> 故障处理</h3><p>大规模分布式系统中，故障不可避免。需设计可靠的错误检测与恢复策略。</p><h4 id="故障检测" tabindex="-1"><a class="header-anchor" href="#故障检测" aria-hidden="true">#</a> 故障检测</h4><p>判断服务器是否宕机不能仅基于网络中断。<br> 一种方法是全量多播（All-to-All Multicasting），但在节点多时效率低：</p><figure><img src="'+h+'" alt="全量多播" tabindex="0" loading="lazy"><figcaption>全量多播</figcaption></figure><p>更好的方式是使用 <strong>Gossip 协议</strong>：</p><ul><li>每个节点维护成员列表及心跳计数。</li><li>周期性随机向其他节点发送心跳，节点间传播心跳。</li><li>未收到心跳时，将成员标记为离线。</li></ul><figure><img src="'+u+'" alt="Gossip 协议" tabindex="0" loading="lazy"><figcaption>Gossip 协议</figcaption></figure><h4 id="临时故障" tabindex="-1"><a class="header-anchor" href="#临时故障" aria-hidden="true">#</a> 临时故障</h4><p>通过 <strong>Hinted Handoff</strong> 提高可用性：<br> 如果某节点暂时离线，可将其数据暂时交由健康节点处理，恢复后再回传。</p><h4 id="永久故障" tabindex="-1"><a class="header-anchor" href="#永久故障" aria-hidden="true">#</a> 永久故障</h4><p>若副本永久不可用，可通过 <strong>Merkle 树</strong> 进行反熵协议（Anti-Entropy）同步数据：</p><figure><img src="'+f+'" alt="Merkle 树" tabindex="0" loading="lazy"><figcaption>Merkle 树</figcaption></figure><p>Merkle 树将数据分块，每块生成哈希，仅对不同块进行比较以减少传输数据量。</p><h4 id="数据中心故障" tabindex="-1"><a class="header-anchor" href="#数据中心故障" aria-hidden="true">#</a> 数据中心故障</h4><p>自然灾害或硬件问题可能导致数据中心宕机。<br> 为增强韧性，需将数据复制到多个数据中心中。</p><hr><h3 id="系统架构图" tabindex="-1"><a class="header-anchor" href="#系统架构图" aria-hidden="true">#</a> 系统架构图</h3><figure><img src="'+m+'" alt="architecture-diagram" tabindex="0" loading="lazy"><figcaption>architecture-diagram</figcaption></figure><p>主要特性：</p><ul><li>客户端通过简单的 API 与键值存储系统进行通信。</li><li>协调器作为客户端与键值存储之间的代理。</li><li>使用一致性哈希将节点分布在哈希环上。</li><li>系统为去中心化设计，支持自动化的节点添加和删除。</li><li>数据在多个节点上复制以确保可靠性。</li><li>系统无单点故障。</li></ul><p>每个节点需负责的部分任务：</p><figure><img src="'+_+'" alt="node-responsibilities" tabindex="0" loading="lazy"><figcaption>node-responsibilities</figcaption></figure><hr><h3 id="写入路径" tabindex="-1"><a class="header-anchor" href="#写入路径" aria-hidden="true">#</a> 写入路径</h3><figure><img src="'+b+'" alt="write-path" tabindex="0" loading="lazy"><figcaption>write-path</figcaption></figure><ul><li>写请求会被持久化到提交日志（Commit Log）中。</li><li>数据被写入内存缓存。</li><li>当内存缓存满或达到设定阈值时，数据会刷新到磁盘上的 SSTable。</li></ul><p>SSTable（排序字符串表）：保存的是排序好的键值对。</p><hr><h3 id="读取路径" tabindex="-1"><a class="header-anchor" href="#读取路径" aria-hidden="true">#</a> 读取路径</h3><p>当数据存在于内存中时的读取路径：</p><figure><img src="'+y+'" alt="read-path-in-memory" tabindex="0" loading="lazy"><figcaption>read-path-in-memory</figcaption></figure><p>当数据不在内存中时的读取路径：</p><figure><img src="'+x+'" alt="read-path-not-in-memory" tabindex="0" loading="lazy"><figcaption>read-path-not-in-memory</figcaption></figure><ul><li>如果数据在内存中，则直接从内存中获取。否则，去 SSTable 中查找。</li><li>使用布隆过滤器（Bloom Filter）来高效定位 SSTable 中的数据。</li><li>SSTable 返回结果数据后，最终将其返回给客户端。</li></ul><h2 id="第四步-总结" tabindex="-1"><a class="header-anchor" href="#第四步-总结" aria-hidden="true">#</a> 第四步：总结</h2><p>上述讨论涵盖了多个概念和技术，总结如下：</p>',108),C=i("<table><thead><tr><th><strong>目标/问题</strong></th><th><strong>技术</strong></th></tr></thead><tbody><tr><td>存储大规模数据</td><td>使用一致性哈希将负载分散到多台服务器</td></tr><tr><td>高可用的读取</td><td>数据复制、多数据中心架构</td></tr><tr><td>高可用的写入</td><td>使用版本控制和向量时钟解决冲突</td></tr><tr><td>数据集分区</td><td>一致性哈希</td></tr><tr><td>增量扩展</td><td>一致性哈希</td></tr><tr><td>异构环境支持</td><td>一致性哈希</td></tr><tr><td>可调一致性</td><td>使用 Quorum 共识机制</td></tr><tr><td>处理临时故障</td><td>Sloppy Quorum 和 Hinted Handoff</td></tr><tr><td>处理永久故障</td><td>使用 Merkle 树</td></tr><tr><td>数据中心故障处理</td><td>跨数据中心复制</td></tr></tbody></table>",1);function S(A,R){return t(),a("div",null,[k,r(" prettier-ignore "),C])}const D=e(z,[["render",S],["__file","26_design_a_key_value_store.html.vue"]]);export{D as default};
